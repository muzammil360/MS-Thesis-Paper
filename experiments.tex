\section{Experiments and discussion}
In order to validate our approach, we carry out an extensive and in depth experimental evaluation.  We study our proposed approach from three different perspectives: 

\begin{enumerate}
\item time-accuracy trade-off
\item stage-wise analysis
\item noise analysis
\end{enumerate}

We shall start by discussing time-accuracy trade-off. This allows us to study end-to-end performance of pipeline while trading off computational time.  We also do stage-wise analysis where each stage is evaluated independently of other. This helps us understand which stage is acting as bottleneck in terms of performance. Additionally, we also do noise analysis to understand the robustness of system to noise.

\subsection{Time-accuracy trade-off experiment}
In time-accuracy trade off experiment, we study how the data can be processed in less time by compromising performance. We vary certain control parameters (stage 1 threshold in this case) and observe the time it takes to process the data along with the performance of the complete pipeline. Figure \ref{fig:time-acc-tradeoff-ar-mog} shows time-accuracy trade off for varying activity ratios (AR). The trade off curve depicts f1 score on y-axis and normalized processing time on the x-axis. Next we give the definition of normalized processing time. 
$$\text{normalized time} = \frac{\text{total time to process video data}}{\text{length of video data}}$$
It is clear that as the f1 score goes up, the normalized processing time also goes up, indicating the trade off. Further, notice that the trade off curve shifts to the left as AR decreases. This is expected as stage 1 filters more and more frames with increasing threshold and thus lesser frames are processed by stage 2.The synthetic dataset parameters using in this experiment are shown in table \ref{table:fig1_data_params}. 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{images/time-acc-tradeoff-ar-mog.png}
    \caption{Time-accuracy trade off for varying AR}
    \label{fig:time-acc-tradeoff-ar-mog}
\end{figure}

\begin{table}
\centering
\caption{Synthetic data parameters for time-accuracy trade off} \vspace{5pt}
\label{table:fig1_data_params}
\begin{tabular}{|l|l|}
\hline
parameter             & value  \\ \hline \hline
p                     & 1\%    \\ 
$\mu$    & 0.50\% \\ 
$\sigma$ & 0.20\% \\ \hline
\end{tabular}
\end{table}

\subsection{Stage-wise analysis experiments}
In this part, we analyse both stage 1 and 2 independently. F1 score is primarily used for analysis as it helps in selecting optimum operating threshold. Apart from that, we use AUC (Area Under the Curve) as the evaluation metric since it is not affected by class imbalance. We naturally have class imbalance since very few trespassing frames exist as compared to other frames. Table \ref{table:auc-time-analysis-s1} shows AUC and mean processing time for both stages. Stage 1 has AUC of 0.94 whereas stage 2 shows an AUC of 0.81. The first stage takes 30 ms  (on average) to process a frame while stage 2 takes around 500 ms on $1080 \times 960$ sized frame. This shows that stage 1 is approx. $16.7$ times faster than stage 2 which resonates with our goal stated in section \ref{sec:goal}. 

Figure \ref{fig:f1-analysis-mog} shows how f1 score of stage 1 changes w-r-t threshold (percentage of foreground pixels). At $0.1\%$, it achieves maximum f1 score of 0.91. Therefore, the stage 1 should be operated at this threshold.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{images/f1-analysis-mog.png}
    \caption{Stage 1 evaluation}
    \label{fig:f1-analysis-mog}
\end{figure}

Figure \ref{fig:f1-analysis-s2} shows the f1 score variation for stage 2. Y-axis indicates f1 score whereas x-axis varies prediction probability threshold $\tau$. It is clear that maximum f1 score of 0.89 is achieved on $\tau=0.3$. Therefore, stage 2 should be operated at this threshold.

Note that Faster-RCNN, which is the backbone of our stage 2, produces multiple object predictions corresponding to each input image\footnote{image and frame have been used interchangeably in this text}. However, we model our problem as a binary classification of input frame as trespassing frame or non-trespassing frame. Therefore, we need to map Faster-RCNN predictions to binary labels i.e. trespassing or non-trespassing. We achieve this mapping by the following definition:

$$
\text{prediction} = 
\begin{cases}
% 1, &    \text{\footnotesize{if there is at least one valid person detection}} \\
1, &    \text{if any valid person detection exists} \\
0, &    \text{otherwise}
\end{cases}
$$
where \\
$\text{valid person detection} = \hat{p}_i>\tau \quad \& \quad IoU(\hat{b}_i,b_j)>0.5$ \\
$\hat{b}_i =i^{th} \text{ prediction bounding box}$ \\
$b_j =j^{th} \text{ ground truth bounding box}$ \\
$\hat{p}_i = i^{th} \text{prediction probability}$ \\
$\tau =  \text{prediction probability threshold}$

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{images/f1-analysis-s2.png}
    \caption{Stage 2 evaluation}
    \label{fig:f1-analysis-s2}
\end{figure}



\begin{table}
\centering
\caption{Stage 1 AUC and time analysis} \vspace{5pt}
\label{table:auc-time-analysis-s1}
\begin{tabular}{|l|l|c|}
\hline
stage   	& AUC     & mean processing \\
            &         &  time (ms)  \\ \hline \hline
stage 1     & 0.94    & 30    \\
stage 2     & 0.81    & 500  \\ \hline
\end{tabular}
\end{table}


\subsection{Noise analysis experiments}
Third and final part of our experimental evaluation is noise analysis. In this part, we evaluate the robustness of stage 1 against noise. In terms of noise, we have 3 parameters: $p, \mu, \text{ and } \sigma$. Description of these parameters has been discussed in table \ref{table:noise-params}. To study the influence of one parameter, we vary it while keeping the others constant. 

Table \ref{table:noise-analysis-auc-mog} shows AUC for stage 1 varying $p$ and $\mu$. We use the noise parameters ($AR=0.5$, $\mu=0.5\%$, $\sigma=0.2\%$) while varying $p$ and ($AR=0.5$, $p=2\%$, $\sigma=0.2\%$) while varying $\mu$. For both $p$ and $\mu$, it is clear that increase in noise level decreases the AUC of stage 1.  This result is also verified by f1 score plot of stage 1. Figure \ref{fig:noise-analysis-mog-p} and \ref{fig:noise-analysis-mog-mu} show the effect of change in $p$ and $\mu$ respectively. Figure \ref{fig:noise-analysis-mog-p} shows that as $p$ increases, the whole f1 score curve shit downward. This indicates the degradation of performance with increase in $p$. Similar observation can also be made in figure \ref{fig:noise-analysis-mog-mu} (showing the effect of change in $\mu$); however, the change is less prominent in this case.  


\begin{table}
\centering
\caption{Noise analysis - AUC for varying $p$ and $\mu$} \vspace{5pt}
\label{table:noise-analysis-auc-mog}

\begin{tabular}{l r}

\begin{tabular}{|l|l|}
\hline
$p$         & AUC  \\ \hline \hline
2\%         & 0.93   \\
4\%         & 0.87    \\ 
6\%         & 0.83      \\ 
8\%         & 0.78       \\ \hline
\end{tabular}


\begin{tabular}{|l|l|}
\hline
$\mu$         & AUC  \\ \hline \hline
0.5\%         & 0.93   \\
0.7\%         & 0.92    \\ 
0.9\%         & 0.91      \\ 
1.1\%         & 0.88       \\ \hline
\end{tabular}

\end{tabular}

\end{table}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{images/noise-analysis-mog-p.png}
    \caption{Noise analysis - varying $p$}
    \label{fig:noise-analysis-mog-p}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{images/noise-analysis-mog-mu.png}
    \caption{Noise analysis - varying $\mu$}
    \label{fig:noise-analysis-mog-mu}
\end{figure}