\section{Experimental evaluation}
\label{sec:exp-eval}
\textbf{Experimental setup:}
All our experiments have been carried out using single Nvidia Tesla K20 GPU. We use pytorch based Faster-RCNN implementation\footnote{https://github.com/facebookresearch/maskrcnn-benchmark} along OpenCV v4.0.0 running on Red Hat Linux based HPC cluster. 

\subsection{Dataset}
The dataset used for experimental evaluation is VIRAT 2.0 \cite{virat20}. This video dataset has been developed for activity classification and is with human activity; meaning frames mostly contain humans in motion. In contrast, trespassing data is known to be extremely sparse because trespassing is an anomaly instead of common steady traffic pattern. To model this, we augment the VIRAT 2.0 dataset to control the amount of activity to background ratio as described below.

\vspace{5pt}
\subsubsection{Synthetic dataset generator}
\label{sec:synthetic-dataset-generator}
Figure \ref{fig:synthetic-dataset-generator} illustrates our synthetic dataset generator which adopts the following steps: 
\begin{enumerate} 
    \item identify background frame
    \item make background block(s)
    \item write background block(s)
    \item write activity block(s)
    \item repeat (3) and (4)
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth,trim={0 50 0 200},clip]{images/synthetic-dataset-generator}
    \caption{Synthetic dataset generator}
    \label{fig:synthetic-dataset-generator}
\end{figure}

Step 1 is human labor intensive but simple. We manually scroll through a video and identify a variety of frames with no human. We call these frames, the background frames. In step 2, we repeat each background frame $\Delta \times fps$ times to generate the corresponding background block. Here, the $fps$ denotes the frames-per-second of the original video and $\Delta$ indicates the target length of background blocks in seconds. In step 3, we randomly select a certain number of  background blocks (determined in step 2) and write them to output video stream. The exact number of background blocks written depends on activity ratio, discussed at the end of this subsection. Step 4 writes the activity block in output video stream. An activity block is simply a section of the original video. By default, we use $30s$ long activity blocks. The length of each background block is also kept at $30s$ by default. Figure \ref{fig:synthetic-video} explains the concept of activity block and synthetic video.  

\begin{figure}
    \centering
    \includegraphics[width=\linewidth,trim={0 130 0 130},clip]{images/synthetic-video}
    \caption{Synthetic video illustration}
    \label{fig:synthetic-video}
\end{figure}

An important metric associated with this procedure is \textit{Activity Ratio}. It captures the fraction of activity present in the output video. It is defined as: 
$$ \text{Activity Ratio} = \text{AR} = \frac{1}{1+nBG} $$
where $nBG=$ number of background blocks per activity block. Figure \ref{fig:synthetic-video} has $nBG=1$. Table \ref{table:activity-ratio} explains the relationship between $nBG$ and AR. 


\begin{table}
\centering
\caption{Relationship of number of background blocks and activity ratio} \vspace{5pt}
\label{table:activity-ratio}
\begin{tabular}{@{}| l | l | l | @{}} \hline
nBG & nAB:nBG & AR   \\ \hline \hline
1   & 1:1     & 0.5  \\ \hline
3   & 1:3     & 0.25 \\ \hline
5   & 1:5     & 0.16 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Adding noise}
Outdoor surveillance videos are often subjected to environmental challenges such as rain and snow. In order to test the robustness of our approach in those challenging situations, we add noise to our synthetic data. Salt and pepper noise \cite{marques2011practical} is known for modeling rain and snow effect, therefore we use it in our experiments. 
Table \ref{table:noise-params} describes the parameters that control the level of noise. 

To add noise, we first select $p\%$ of frames from each background block. Each frame is equally likely to be selected. Now we draw an integer $r$ from the normal distribution with parameters $\mu$ and $\sigma$. For each selected frame, we select $r$ pixels and add noise to them. Again all pixels are equally likely. 

\begin{table}
\centering
\caption{Noise parameters}  \vspace{5pt}
\label{table:noise-params}
\begin{tabular}{|l|l|}
\hline
params & description                              \\ \hline \hline
$p$          & percentage of noisy frames in BG block  \\ \hline
$\mu$        & avg. number of noisy pixels in noisy frame     \\ \hline
$\sigma$     & standard deviation of number of noisy pixels     \\ \hline
\end{tabular}
\end{table}
